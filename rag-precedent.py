# !pip install google-cloud-aiplatform langchain langchain-google-vertexai langchain-community

import os
from google.cloud import aiplatform
from langchain_google_vertexai import VertexAI, VertexAIEmbeddings
from langchain_community.vectorstores import MatchingEngine
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_core.documents import Document

# ==========================================
# 1. í™˜ê²½ ì„¤ì •
# ==========================================
PROJECT_ID = "your-project-id"       # í”„ë¡œì íŠ¸ ID ì…ë ¥ (Console ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸)
LOCATION = "us-central1"             # ë¦¬ì „ (ì„œìš¸ì€ asia-northeast3)
INDEX_ID = "your-index-id"           # Vertex AI Vector Search Index ID
ENDPOINT_ID = "your-endpoint-id"     # Vertex AI Vector Search Endpoint ID

# ==========================================
# 2. ì¸ì¦ ì„¤ì • (ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ ì‚¬ìš©)
# ==========================================
# Google Cloud Consoleì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • JSON í‚¤ ë‹¤ìš´ë¡œë“œ í›„ ê²½ë¡œ ì§€ì •
# 1. Console â†’ "IAM ë° ê´€ë¦¬ì" â†’ "ì„œë¹„ìŠ¤ ê³„ì •"
# 2. ì„œë¹„ìŠ¤ ê³„ì • ë§Œë“¤ê¸° â†’ ì—­í•  ë¶€ì—¬: "Vertex AI User", "Storage Admin"
# 3. í‚¤ ìƒì„± â†’ JSON ë‹¤ìš´ë¡œë“œ
SERVICE_ACCOUNT_KEY_PATH = "path/to/your-service-account-key.json"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = SERVICE_ACCOUNT_KEY_PATH

# Vertex AI ì´ˆê¸°í™”
aiplatform.init(project=PROJECT_ID, location=LOCATION)

# ==========================================
# 3. LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
# ==========================================

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (Vertex AI Embeddings)
embeddings = VertexAIEmbeddings(
    model_name="textembedding-gecko@003",  # ë˜ëŠ” text-embedding-004
    project=PROJECT_ID,
    location=LOCATION
)

# LLM ì´ˆê¸°í™” (Vertex AI Gemini)
llm = VertexAI(
    model_name="gemini-1.5-pro",  # ë˜ëŠ” gemini-1.5-flash
    project=PROJECT_ID,
    location=LOCATION,
    temperature=0.2,
    max_output_tokens=1024,
)

# ==========================================
# 4. ë¬¸ì„œ ì¤€ë¹„ ë° Vector Store ì—°ê²°
# ==========================================

# ì˜ˆì œ ë¬¸ì„œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” PDF, ì›¹ì‚¬ì´íŠ¸ ë“±ì—ì„œ ë¡œë“œ)
sample_texts = [
    "LGì´ë…¸í…ì€ ì „ìë¶€í’ˆ ì „ë¬¸ê¸°ì—…ì…ë‹ˆë‹¤. ì¹´ë©”ë¼ ëª¨ë“ˆ, ê¸°íŒ, ëª¨í„° ë“±ì„ ìƒì‚°í•©ë‹ˆë‹¤.",
    "LGì´ë…¸í…ì˜ ì£¼ìš” ì œí’ˆì€ ìŠ¤ë§ˆíŠ¸í°ìš© ì¹´ë©”ë¼ ëª¨ë“ˆì…ë‹ˆë‹¤.",
    "íšŒì‚¬ëŠ” 2008ë…„ LGì „ìì˜ ë¶€í’ˆ ì‚¬ì—…ë¶€ê°€ ë¶„ì‚¬í•˜ì—¬ ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë³¸ì‚¬ëŠ” ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
    "LGì´ë…¸í…ì€ Appleì˜ ì£¼ìš” ì¹´ë©”ë¼ ëª¨ë“ˆ ê³µê¸‰ì—…ì²´ì…ë‹ˆë‹¤.",
]

# Document ê°ì²´ë¡œ ë³€í™˜
documents = [Document(page_content=text, metadata={"source": f"doc_{i}"})
             for i, text in enumerate(sample_texts)]

# í…ìŠ¤íŠ¸ ë¶„í•  (ê¸´ ë¬¸ì„œì˜ ê²½ìš°)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    length_function=len,
)
split_docs = text_splitter.split_documents(documents)

print(f"ğŸ“„ ì´ {len(split_docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ")

# ==========================================
# 5. Vertex AI Vector Search ì—°ê²°
# ==========================================
# Option 1: ê¸°ì¡´ Index ì‚¬ìš© (ì´ë¯¸ ìƒì„±ëœ ê²½ìš°)
# INDEX_IDì™€ ENDPOINT_IDë¥¼ Consoleì—ì„œ í™•ì¸í•˜ì—¬ ì…ë ¥

vector_store = MatchingEngine.from_components(
    project_id=PROJECT_ID,
    region=LOCATION,
    index_id=INDEX_ID,
    endpoint_id=ENDPOINT_ID,
    embedding=embeddings,
)

print("âœ… Vector Store ì—°ê²° ì™„ë£Œ")

# ==========================================
# Option 2: ìƒˆë¡œìš´ ë¬¸ì„œë¡œ Vector Store ìƒì„± ë° ì—…ë¡œë“œ
# ==========================================
# ì£¼ì˜: ì´ ë°©ë²•ì€ ìƒˆë¡œìš´ Indexì™€ Endpointë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ì‹œê°„ ì†Œìš”: ì•½ 1ì‹œê°„)
#
# vector_store = MatchingEngine.from_documents(
#     documents=split_docs,
#     embedding=embeddings,
#     project_id=PROJECT_ID,
#     region=LOCATION,
#     gcs_bucket_name="your-bucket-name",  # GCS ë²„í‚· í•„ìš”
#     index_id="my_langchain_index",
#     endpoint_id="my_langchain_endpoint",
# )

# ==========================================
# 6. RAG Chain êµ¬ì„±
# ==========================================

# Retriever ìƒì„± (ìœ ì‚¬ë„ ê²€ìƒ‰)
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}  # ìƒìœ„ 3ê°œ ë¬¸ì„œ ê²€ìƒ‰
)

# RetrievalQA Chain ìƒì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",  # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ëª¨ë‘ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
    retriever=retriever,
    return_source_documents=True,  # ê²€ìƒ‰ëœ ë¬¸ì„œë„ í•¨ê»˜ ë°˜í™˜
    verbose=True
)

print("âœ… RAG Chain êµ¬ì„± ì™„ë£Œ")

# ==========================================
# 7. ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
# ==========================================

# ì‚¬ìš©ì ì§ˆë¬¸
question = "LGì´ë…¸í…ì˜ ì£¼ìš” ì œí’ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"

print(f"\nâ“ ì§ˆë¬¸: {question}")
print("="*60)

# RAG ì‹¤í–‰
result = qa_chain.invoke({"query": question})

# ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ’¡ ë‹µë³€:\n{result['result']}")
print("\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
for i, doc in enumerate(result['source_documents'], 1):
    print(f"  {i}. {doc.page_content} (ì¶œì²˜: {doc.metadata.get('source', 'N/A')})")

# ==========================================
# 8. ì¶”ê°€ ì§ˆë¬¸ ì˜ˆì œ
# ==========================================

def ask_question(question: str):
    """RAG ì‹œìŠ¤í…œì— ì§ˆë¬¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    print(f"\n{'='*60}")
    print(f"â“ ì§ˆë¬¸: {question}")
    print('='*60)

    result = qa_chain.invoke({"query": question})

    print(f"\nğŸ’¡ ë‹µë³€:\n{result['result']}")
    print("\nğŸ“š ì°¸ì¡° ë¬¸ì„œ:")
    for i, doc in enumerate(result['source_documents'], 1):
        print(f"  {i}. {doc.page_content}")

    return result

# ì—¬ëŸ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    questions = [
        "LGì´ë…¸í…ì€ ì–¸ì œ ì„¤ë¦½ë˜ì—ˆë‚˜ìš”?",
        "LGì´ë…¸í…ì˜ ë³¸ì‚¬ëŠ” ì–´ë””ì— ìˆë‚˜ìš”?",
        "LGì´ë…¸í…ì˜ ì£¼ìš” ê³ ê°ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
    ]

    for q in questions:
        ask_question(q)
