import os
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì„¤ì • (Google API í‚¤ í•„ìš”)
# ==========================================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”: GOOGLE_API_KEY
os.environ["GOOGLE_API_KEY"] = "your-google-api-key"

# LLM ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(
    model="gemini-flash-lite-latest",
    temperature=0,  # ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
    convert_system_message_to_human=True  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ë³€í™˜
)

embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001"
)

# ==========================================
# 2. ë°ì´í„° ì¤€ë¹„ (ê°€ìƒì˜ ì‚¬ë‚´ ê·œì • ë°ì´í„°)
# ==========================================
raw_text = """
[2026ë…„ ì£¼ì‹íšŒì‚¬ ë­ì²´ì¸ ì‚¬ë‚´ ì—…ë¬´ ê°€ì´ë“œë¼ì¸]

1. ê·¼ë¬´ ì‹œê°„
- ê¸°ë³¸ ê·¼ë¬´ ì‹œê°„ì€ ì˜¤ì „ 10ì‹œë¶€í„° ì˜¤í›„ 7ì‹œê¹Œì§€ì…ë‹ˆë‹¤.
- ìœ ì—° ê·¼ë¬´ì œë¥¼ ì‹œí–‰í•˜ê³  ìˆì–´, ì˜¤ì „ 8ì‹œ~11ì‹œ ì‚¬ì´ì— ììœ ë¡­ê²Œ ì¶œê·¼ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- ì ì‹¬ì‹œê°„ì€ 12ì‹œ 30ë¶„ë¶€í„° 1ì‹œ 30ë¶„ê¹Œì§€ 1ì‹œê°„ì…ë‹ˆë‹¤.

2. ì¬íƒê·¼ë¬´ ê·œì • (RAG í•µì‹¬ í…ŒìŠ¤íŠ¸ êµ¬ê°„)
- ì£¼ 2íšŒ ì¬íƒê·¼ë¬´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. (í™”ìš”ì¼, ëª©ìš”ì¼ ê¶Œì¥)
- ì¬íƒê·¼ë¬´ ì‹ ì²­ì€ ì „ë‚  ì˜¤í›„ 4ì‹œê¹Œì§€ ì‚¬ë‚´ ë©”ì‹ ì € 'ìŠ¬ë™'ì˜ #wfh ì±„ë„ì— ë‚¨ê²¨ì•¼ í•©ë‹ˆë‹¤.
- ê¸´ê¸‰í•œ íšŒì˜ê°€ ì¡í ê²½ìš°, íŒ€ì¥ì˜ ìŠ¹ì¸ í•˜ì— ì¬íƒê·¼ë¬´ê°€ ì·¨ì†Œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì œì£¼ë„ ë“± ì›ê²©ì§€ ê·¼ë¬´(ì›Œì¼€ì´ì…˜)ëŠ” ë¶„ê¸°ë‹¹ 1íšŒ, ìµœëŒ€ 1ì£¼ì¼ ì§€ì›ë©ë‹ˆë‹¤.

3. ë¹„ìš© ì²­êµ¬
- ì•¼ê·¼ ì‹ëŒ€ëŠ” ì˜¤í›„ 8ì‹œ ì´í›„ í‡´ê·¼ ì‹œ 15,000ì›ê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤.
- ë²•ì¸ì¹´ë“œ ì˜ìˆ˜ì¦ì€ ë§¤ì›” ë§ì¼ê¹Œì§€ ì¬ë¬´íŒ€ì— ì‹¤ë¬¼ë¡œ ì œì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
"""

# LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
docs = [Document(page_content=raw_text)]

# ==========================================
# 3. ë°ì´í„° ë¶„í•  (Splitting)
# ==========================================
# ê¸´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê¸° ì¢‹ê²Œ ì‘ì€ ì²­í¬(Chunk)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
splits = text_splitter.split_documents(docs)

print(f"ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(splits)}ê°œ")

# ==========================================
# 4. ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• (Indexing)
# ==========================================
# ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ì—¬ FAISS(ë¡œì»¬ ê²€ìƒ‰ê¸°)ì— ì €ì¥í•©ë‹ˆë‹¤.
# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì´ ë¶€ë¶„ì„ Vertex AI Vector Searchë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)

# ê²€ìƒ‰ê¸°(Retriever) ìƒì„±
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 2} # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 2ê°œë§Œ ì°¸ì¡°
)

# ==========================================
# 5. RAG ì²´ì¸ ìƒì„± (Modern LangChain 1.x approach)
# ==========================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: ê²€ìƒ‰ëœ ì •ë³´(Context)ë¥¼ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µí•˜ë„ë¡ ì§€ì‹œ
template = """ë‹¹ì‹ ì€ íšŒì‚¬ì˜ ì¸ì‚¬ ê·œì •ì„ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ AI ë´‡ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ [ì°¸ê³  ë¬¸ì„œ] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì£„ì†¡í•©ë‹ˆë‹¤, í•´ë‹¹ ë‚´ìš©ì€ ê·œì •ì— ë‚˜ì™€ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{context}

ì§ˆë¬¸: {question}
ë‹µë³€:"""

prompt = ChatPromptTemplate.from_template(template)

# ë¬¸ì„œë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·í•˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# LCEL (LangChain Expression Language)ë¡œ ì²´ì¸ êµ¬ì„±
qa_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ==========================================
# 6. í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰
# ==========================================
def ask_bot(question):
    print(f"\nğŸ™‹ ì§ˆë¬¸: {question}")
    result = qa_chain.invoke(question)
    print(f"ğŸ¤– ë‹µë³€: {result}")

    # ì°¸ì¡° ë¬¸ì„œë¥¼ ë³´ë ¤ë©´ retrieverë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    # docs = retriever.invoke(question)
    # print(f"ğŸ“„ ì°¸ì¡° ë¬¸ì„œ: {docs[0].page_content[:50]}...")

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
ask_bot("ì¬íƒê·¼ë¬´ ì‹ ì²­ì€ ì–¸ì œê¹Œì§€ í•´ì•¼ í•´?")
ask_bot("ì•¼ê·¼ ì‹ëŒ€ëŠ” ì–¼ë§ˆê¹Œì§€ ì§€ì›ë¼?")
ask_bot("ì—°ì°¨ëŠ” ë©°ì¹ ê¹Œì§€ ì“¸ ìˆ˜ ìˆì–´?") # ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš© í…ŒìŠ¤íŠ¸