{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <code>stockprice5_pytorch.npz</code> 파일을 github에서 다운로드 받아서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stockprice5_pytorch.npz...\n",
      "stockprice5_pytorch.npz downloaded.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download data files if not exist\n",
    "data_urls = {\n",
    "    'stockprice5_pytorch.npz': 'https://github.com/nongaussian/class-2026-lginnotek-llm/raw/refs/heads/main/stockprice5_pytorch.npz'\n",
    "}\n",
    "\n",
    "for filename, url in data_urls.items():\n",
    "    if not os.path.exists(filename):\n",
    "        print(f'Downloading {filename}...')\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f'{filename} downloaded.')\n",
    "    else:\n",
    "        print(f'{filename} already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('stockprice5_pytorch.npz')\n",
    "x_train = npz['x_train']\n",
    "y_train = npz['y_train']\n",
    "x_test = npz['x_test']\n",
    "y_test = npz['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13760, 60, 5) (13760, 1) (4065, 60, 5) (4065, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM & TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 4])\n",
      "torch.Size([1, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch LSTM test\n",
    "# Input shape: (batch, seq_len, input_size)\n",
    "inputs = torch.randn(32, 10, 8)\n",
    "lstm = nn.LSTM(input_size=8, hidden_size=4, batch_first=True)\n",
    "output, (h_n, c_n) = lstm(inputs)\n",
    "print(output.shape)  # (batch, seq_len, hidden_size) - 모든 타임스텝의 출력\n",
    "print(h_n.shape)     # (num_layers, batch, hidden_size) - 마지막 hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch LSTM returns both sequence outputs and states by default\n",
    "lstm = nn.LSTM(input_size=8, hidden_size=4, batch_first=True)\n",
    "whole_seq_output, (final_state_h, final_state_c) = lstm(inputs)\n",
    "print(whole_seq_output.shape)  # (32, 10, 4) - 전체 시퀀스 출력\n",
    "print(final_state_h.shape)     # (1, 32, 4) - 마지막 hidden state\n",
    "print(final_state_c.shape)     # (1, 32, 4) - 마지막 cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 10])\n",
      "torch.Size([4, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch TimeDistributed equivalent\n",
    "# For Conv2D over time, we reshape (batch, seq_len, input_size) -> (batch*seq_len, input_size)\n",
    "inputs = torch.randn(4, 128, 10)  # (batch, seq_len, input_size)\n",
    "batch, seq_len, input_size = inputs.shape\n",
    "print(inputs.shape)  # (4, 128, 10)\n",
    "\n",
    "dense_layer = nn.Linear(input_size, 16) # output size = 16\n",
    "# Reshape, apply conv, then reshape back\n",
    "inputs_reshaped = inputs.view(batch * seq_len, input_size)\n",
    "outputs = dense_layer(inputs_reshaped)\n",
    "outputs = outputs.view(batch, seq_len, 16)\n",
    "print(outputs.shape)  # (4, 128, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch RepeatVector equivalent\n",
    "# Dense(32) -> RepeatVector(3) : (batch, 32) -> (batch, 3, 32)\n",
    "x = torch.randn(4, 32)\n",
    "dense = nn.Linear(32, 32)\n",
    "x = dense(x)\n",
    "# RepeatVector: unsqueeze and repeat\n",
    "x = x.unsqueeze(1).repeat(1, 3, 1)\n",
    "print(x.shape)  # (4, 3, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "n_rnn_layers = 3\n",
    "x_dims = 8\n",
    "latent_dims = 8 # assumed to be the same as x_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, x_dims, n_rnn_layers, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # TimeDistributed Dense equivalent: Linear layer applied to each timestep\n",
    "        self.fc_input = nn.Linear(input_dim, x_dims)\n",
    "        \n",
    "        # Stacked LSTM layers\n",
    "        # PyTorch LSTM can have multiple layers built-in\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=x_dims,\n",
    "            hidden_size=x_dims,\n",
    "            num_layers=n_rnn_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_rnn_layers > 1 else 0  # dropout between LSTM layers\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_output = nn.Linear(x_dims, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_dim)\n",
    "        \n",
    "        # Apply linear layer to each timestep (TimeDistributed equivalent)\n",
    "        x = self.relu(self.fc_input(x))  # (batch, seq_len, x_dims)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # lstm_out: (batch, seq_len, x_dims) - all timestep outputs\n",
    "        # h_n: (n_layers, batch, x_dims) - last hidden state for each layer\n",
    "        \n",
    "        # Use the last hidden state from the last layer\n",
    "        last_hidden = h_n[-1]  # (batch, x_dims)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.fc_output(last_hidden)  # (batch, 1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def build_encoder():\n",
    "    model = Encoder(input_dim, x_dims, n_rnn_layers, dropout=0.2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (fc_input): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (lstm): LSTM(8, 8, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc_output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_encoder()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[-0.0389]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test if model works\n",
    "tmp_x_batch = torch.randn(1, 32, input_dim).to(device)\n",
    "output = model(tmp_x_batch)\n",
    "print(output.shape)  # (1, 1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "x_train_tensor = torch.FloatTensor(x_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "x_test_tensor = torch.FloatTensor(x_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.L1Loss()  # Mean Absolute Error\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    return total_loss / len(test_loader.dataset)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - {elapsed:.1f}s - \"\n",
    "          f\"loss: {train_loss:.4f} - val_loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        idx = np.random.randint(x_test.shape[0])\n",
    "        x_sample = torch.FloatTensor(x_test[idx]).unsqueeze(0).to(device)\n",
    "        y_pred = model(x_sample).cpu().numpy()[0, 0]\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(x_test[idx, :, 0])\n",
    "        plt.axhline(y_test[idx], color='r', label='True')\n",
    "        plt.axhline(y_pred, color='g', label='Predicted')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
