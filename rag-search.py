from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import os

# API í‚¤ ì„¤ì •
os.environ["GOOGLE_API_KEY"] = "your-api-key"

# 1. ì €ì¥ëœ íŒë¡€ ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# rag-build-index.pyì™€ ë™ì¼í•œ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")

# 'allow_dangerous_deserialization=True'ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¡œì»¬ íŒŒì¼ì¼ ê²½ìš°ì—ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
new_db = FAISS.load_local(
    "precedent_index",
    embeddings,
    allow_dangerous_deserialization=True
)

# 2. ê²€ìƒ‰ê¸°(Retriever)ë¡œ ë³€í™˜ - ìœ ì‚¬í•œ íŒë¡€ 3ê°œ ê²€ìƒ‰
retriever = new_db.as_retriever(search_kwargs={"k": 3})

# 3. LLM ì„¤ì • (Gemini 2.0 Flash)
llm = ChatGoogleGenerativeAI(model="gemini-flash-lite-latest", temperature=0)

# 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë²•ë¥  ìƒë‹´ìš©)
prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ íŒë¡€ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì°¸ê³  íŒë¡€]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€ ì§€ì¹¨]
1. ì°¸ê³  íŒë¡€ì˜ ì‚¬ì‹¤ê´€ê³„ì™€ ì§ˆë¬¸ì˜ ìƒí™©ì„ ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.
2. ê´€ë ¨ íŒë¡€ì˜ ë²•ì› íŒë‹¨ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
3. ì°¸ê³ í•œ íŒë¡€ì˜ ì‚¬ê±´ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
4. ì‹¤ì œ ë²•ì  ì¡°ì–¸ì´ ì•„ë‹Œ ì°¸ê³ ìš© ì •ë³´ì„ì„ ëª…ì‹œí•˜ì„¸ìš”.

ë‹µë³€:
""")

# 5. ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜
def format_docs(docs):
    print(docs)
    return "\n\n".join(doc.page_content for doc in docs)

# 6. LCEL ì²´ì¸ êµ¬ì„±
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# 7. ì§ˆë¬¸í•˜ê¸° í•¨ìˆ˜
def ask_question(query):
    print(f"\nğŸ™‹ ì§ˆë¬¸: {query}")
    result = rag_chain.invoke(query)
    print(f"ğŸ¤– ë‹µë³€: {result}")

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    #ask_question("AëŠ” Bì˜ ë°°ìš°ìì¸ë° Bê°€ íšŒì‚¬ë¥¼ ë‹¤ë‹ˆë‹¤ ê°„ê²½í™” ì§„ë‹¨ì„ ë°›ì•„ ì¼ì„ ë”ì´ìƒ ëª»í•˜ê³  1ë…„ì „ì— í‡´ì‚¬ë¥¼ í•˜ì˜€ê³  6ê°œì›”ì „ì— ê°„ì„¸í¬ì•” ì§„ë‹¨ì„ ë°›ì•„ 3ê°œì›”ì „ì— ì‚¬ë§í•˜ì˜€ë‹¤. AëŠ” ì§ì¥ ë‚´ ê´´ë¡­í˜, ë”°ëŒë¦¼, í­ì–¸, í­í–‰, ì‚¬ì§ ê°•ìš” ë“±ì€ ì—†ì—ˆë˜ ê²ƒìœ¼ë¡œ íŒëª…ë˜ì—ˆë‹¤. AëŠ” ì‚°ì—…ì¬í•´ë³´ìƒì„ ë°›ì„ìˆ˜ ìˆì„ê¹Œ?")
    ask_question("AëŠ” ì•„ì£¼ ìœ ëª…í•œ ì¿ í‚¤ ì œê³¼ì  Bì˜ ìƒí‘œê°€ ì•„ì§ ìƒí‘œë“±ë¡ì´ ì•ˆëœ ê²ƒì„ ì•Œê³  ìê¸°ê°€ ë¨¼ì € ìƒí‘œ ë“±ë¡ì„ í•˜ë ¤ê³  í–ˆê³ , ì´ë¥¼ Bê°€ ìš°ì—°íˆ ì•Œì•„ë‚´ê³  ìƒí‘œ ë“±ë¡ ì·¨í•˜ ì†Œì†¡ì„ í–ˆì–´. ê·¸ë¦¬ê³  BëŠ” Aì—ê²Œ ì €ì‘ê¶Œ ì¹¨í•´ ì†í•´ë°°ìƒê¹Œì§€ ê±¸ì—ˆì–´. BëŠ” ì†Œì†¡ì—ì„œ ì´ê¸¸ ìˆ˜ ìˆì„ê¹Œ?")
    #ask_question("2020í—ˆ4570")